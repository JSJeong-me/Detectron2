{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "image-segmentation-using-detectron2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/Detectron2/blob/main/plant_segmentation_using_detectron2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHI19TOWqpd1"
      },
      "source": [
        "# Image segmentation using Detectron2\n",
        "\n",
        "## Using Detectron2 and mask R-CNN it is possible to isolate each leaf from the input image and extract the most prominent one for later analysis.\n",
        "\n",
        "### Steps involved:\n",
        "\n",
        "* Download and install detectron2 and other dependancies\n",
        "\n",
        "* Hand annotate images with the objects mask (not covered in this kernel) - google \"labelme\" and \"training detectron2 on custom dataset\" \n",
        "\n",
        "* Train detectron2 (not covered in this kernel) \n",
        "\n",
        "* Load pretrained weights into detectron2\n",
        "\n",
        "* Infer image masks and identifiy prominent objects\n",
        "\n",
        "* Mask and extract from original image\n",
        "\n",
        "* Crop and rotate object to fit\n",
        "\n",
        "![Masked1](https://i.imgur.com/tnC1ljY.jpg \"Masked Leaf 1\")\n",
        "\n",
        "![Masked](https://i.imgur.com/nemK62H.jpg \"Masked Leaf\")\n",
        "\n",
        "\n",
        "### To Do:\n",
        "\n",
        "* Futher training of the mask R-CNN model to improve segmentation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXXYAIEqpd6"
      },
      "source": [
        "# How to!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkU7TW_cqpd7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScQRNHvbqpd7"
      },
      "source": [
        "### Basic recipe for inferance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_21fvZDqpd8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6piI1Ze0qpd9"
      },
      "source": [
        "### First we will list out all the files in the directory for later use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Y1elGVqpd9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-11-03T02:30:21.956695Z",
          "iopub.execute_input": "2021-11-03T02:30:21.956987Z",
          "iopub.status.idle": "2021-11-03T02:30:22.990748Z",
          "shell.execute_reply.started": "2021-11-03T02:30:21.956958Z",
          "shell.execute_reply": "2021-11-03T02:30:22.989805Z"
        },
        "trusted": true,
        "id": "0PvstUrTqpd-"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "file_list = []\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('./'):\n",
        "    for filename in filenames:\n",
        "        file_list.append(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5OHE93Hqpd_"
      },
      "source": [
        "### Lets then download all of the required libraries to the kaggle kernel "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OY0e5LZCqpeB"
      },
      "source": [
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:23:46.864838Z",
          "iopub.execute_input": "2021-11-03T02:23:46.865149Z",
          "iopub.status.idle": "2021-11-03T02:23:47.661672Z",
          "shell.execute_reply.started": "2021-11-03T02:23:46.865117Z",
          "shell.execute_reply": "2021-11-03T02:23:47.660980Z"
        },
        "trusted": true,
        "id": "6Otd9XMKqpeB"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:24:10.633898Z",
          "iopub.execute_input": "2021-11-03T02:24:10.634217Z",
          "iopub.status.idle": "2021-11-03T02:24:10.640819Z",
          "shell.execute_reply.started": "2021-11-03T02:24:10.634185Z",
          "shell.execute_reply": "2021-11-03T02:24:10.639536Z"
        },
        "trusted": true,
        "id": "euEZI7yIqpeC"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:24:05.441433Z",
          "iopub.execute_input": "2021-11-03T02:24:05.441757Z",
          "iopub.status.idle": "2021-11-03T02:24:06.129452Z",
          "shell.execute_reply.started": "2021-11-03T02:24:05.441727Z",
          "shell.execute_reply": "2021-11-03T02:24:06.128648Z"
        },
        "trusted": true,
        "id": "S1tJFbZzqpeD"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:24:17.928014Z",
          "iopub.execute_input": "2021-11-03T02:24:17.928305Z",
          "iopub.status.idle": "2021-11-03T02:24:24.663969Z",
          "shell.execute_reply.started": "2021-11-03T02:24:17.928276Z",
          "shell.execute_reply": "2021-11-03T02:24:24.663113Z"
        },
        "trusted": true,
        "id": "K9hZYFB7qpeE"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "assert torch.__version__.startswith(\"1.9\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:24:34.550229Z",
          "iopub.execute_input": "2021-11-03T02:24:34.550538Z",
          "iopub.status.idle": "2021-11-03T02:25:18.272649Z",
          "shell.execute_reply.started": "2021-11-03T02:24:34.550506Z",
          "shell.execute_reply": "2021-11-03T02:25:18.271661Z"
        },
        "trusted": true,
        "id": "FSIrsOcMqpeE"
      },
      "source": [
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfV--YD2qpeE"
      },
      "source": [
        "### Import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2021-11-03T02:25:34.262795Z",
          "iopub.execute_input": "2021-11-03T02:25:34.263108Z",
          "iopub.status.idle": "2021-11-03T02:25:35.110856Z",
          "shell.execute_reply.started": "2021-11-03T02:25:34.263076Z",
          "shell.execute_reply": "2021-11-03T02:25:35.110066Z"
        },
        "trusted": true,
        "id": "zqnetLV3qpeF"
      },
      "source": [
        "import math  \n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlrOVCMlqpeG"
      },
      "source": [
        "## Detectron2 uses pytorch and makes it amazingly easy to retrain its pretrained model on a custom dataset. I won't go into the method of doing this but there is a wealth of information online. \n",
        "\n",
        "## The python tool \"labelme\" is great for drawing the masks over your images.\n",
        "\n",
        "![labelme](https://i.imgur.com/phNlpnX.jpg \"Label Me\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVCbmcRgqpeG"
      },
      "source": [
        "# Model Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijiYI3rxqpeG"
      },
      "source": [
        "### Below code is to download the pretrained weights from my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:25:51.799386Z",
          "iopub.execute_input": "2021-11-03T02:25:51.799701Z",
          "iopub.status.idle": "2021-11-03T02:25:52.027731Z",
          "shell.execute_reply.started": "2021-11-03T02:25:51.799672Z",
          "shell.execute_reply": "2021-11-03T02:25:52.027011Z"
        },
        "trusted": true,
        "id": "nhu3i3naqpeG"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:25:57.666754Z",
          "iopub.execute_input": "2021-11-03T02:25:57.667063Z",
          "iopub.status.idle": "2021-11-03T02:26:00.990348Z",
          "shell.execute_reply.started": "2021-11-03T02:25:57.667032Z",
          "shell.execute_reply": "2021-11-03T02:26:00.989585Z"
        },
        "trusted": true,
        "id": "FP4TIVPxqpeI"
      },
      "source": [
        "## download the pretrained weights for leaf segmentation.\n",
        "\n",
        "file_id = '17AHanttKcR9B4A0m7QZqwAvaWxGrYYQp'\n",
        "destination = './model.pth'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:26:06.013966Z",
          "iopub.execute_input": "2021-11-03T02:26:06.014248Z",
          "iopub.status.idle": "2021-11-03T02:26:06.023004Z",
          "shell.execute_reply.started": "2021-11-03T02:26:06.014220Z",
          "shell.execute_reply": "2021-11-03T02:26:06.020497Z"
        },
        "trusted": true,
        "id": "FQRl20IsqpeI"
      },
      "source": [
        "#get the predictor\n",
        "def get_predictor():\n",
        "\n",
        "\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "    cfg.DATASETS.TRAIN = ()\n",
        "    cfg.DATALOADER.NUM_WORKERS = 16\n",
        "\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = (8)  # faster, and good enough for this toy dataset\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    \n",
        "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"./model.pth\")\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    return predictor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4F9_JZkqpeJ"
      },
      "source": [
        "# Image manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:26:10.442483Z",
          "iopub.execute_input": "2021-11-03T02:26:10.442804Z",
          "iopub.status.idle": "2021-11-03T02:26:10.466815Z",
          "shell.execute_reply.started": "2021-11-03T02:26:10.442771Z",
          "shell.execute_reply": "2021-11-03T02:26:10.465991Z"
        },
        "trusted": true,
        "id": "-Hbbm7b7qpeJ"
      },
      "source": [
        "#function to get the leaf image.\n",
        "\n",
        "def get_cropped_leaf(img,predictor,return_mapping=False,resize=None):\n",
        "    #convert to numpy    \n",
        "    img = np.array(img)[:,:,::-1]\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    \n",
        "    #get prediction\n",
        "    outputs = predictor(img)\n",
        "    \n",
        "    #get boxes and masks\n",
        "    ins = outputs[\"instances\"]\n",
        "    pred_masks = ins.get_fields()[\"pred_masks\"]\n",
        "    boxes = ins.get_fields()[\"pred_boxes\"]    \n",
        "    \n",
        "    #get main leaf mask if the area is >= the mean area of boxes and is closes to the centre \n",
        "    \n",
        "    masker = pred_masks[np.argmin([calculateDistance(x[0], x[1], int(img.shape[1]/2), int(img.shape[0]/2)) for i,x in enumerate(boxes.get_centers()) if (boxes[i].area()>=torch.mean(boxes.area()).to(\"cpu\")).item()])].to(\"cpu\").numpy().astype(np.uint8)\n",
        "\n",
        "    #mask image\n",
        "    mask_out = cv2.bitwise_and(img, img, mask=masker)\n",
        "    \n",
        "    #find contours and boxes\n",
        "    contours, hierarchy = cv2.findContours(masker.copy() ,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contour = contours[np.argmax([cv2.contourArea(x) for x in contours])]\n",
        "    rotrect = cv2.minAreaRect(contour)\n",
        "    box = cv2.boxPoints(rotrect)\n",
        "    box = np.int0(box)\n",
        "    \n",
        "\n",
        "    #crop image\n",
        "    cropped = get_cropped(rotrect,box,mask_out)\n",
        "\n",
        "    #resize\n",
        "    rotated = MakeLandscape()(Image.fromarray(cropped))\n",
        "    \n",
        "    if not resize == None:\n",
        "        resized = ResizeMe((resize[0],resize[1]))(rotated)\n",
        "    else:\n",
        "        resized = rotated\n",
        "        \n",
        "    if return_mapping:\n",
        "        img = cv2.drawContours(img, [box], 0, (0,0,255), 10)\n",
        "        img = cv2.drawContours(img, contours, -1, (255,150,), 10)\n",
        "        return resized, ResizeMe((int(resize[0]),int(resize[1])))(Image.fromarray(img))\n",
        "    \n",
        "    return resized\n",
        "\n",
        "#function to crop the image to boxand rotate\n",
        "\n",
        "def get_cropped(rotrect,box,image):\n",
        "    \n",
        "    width = int(rotrect[1][0])\n",
        "    height = int(rotrect[1][1])\n",
        "\n",
        "    src_pts = box.astype(\"float32\")\n",
        "    # corrdinate of the points in box points after the rectangle has been\n",
        "    # straightened\n",
        "    dst_pts = np.array([[0, height-1],\n",
        "                        [0, 0],\n",
        "                        [width-1, 0],\n",
        "                        [width-1, height-1]], dtype=\"float32\")\n",
        "\n",
        "    # the perspective transformation matrix\n",
        "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
        "\n",
        "    # directly warp the rotated rectangle to get the straightened rectangle\n",
        "    warped = cv2.warpPerspective(image, M, (width, height))\n",
        "    return warped\n",
        "\n",
        "def calculateDistance(x1,y1,x2,y2):  \n",
        "    dist = math.hypot(x2 - x1, y2 - y1)\n",
        "    return dist  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:26:16.798742Z",
          "iopub.execute_input": "2021-11-03T02:26:16.799064Z",
          "iopub.status.idle": "2021-11-03T02:26:16.814696Z",
          "shell.execute_reply.started": "2021-11-03T02:26:16.799034Z",
          "shell.execute_reply": "2021-11-03T02:26:16.813840Z"
        },
        "trusted": true,
        "id": "hzldgw0bqpeJ"
      },
      "source": [
        "#image manipulations \n",
        "\n",
        "class ResizeMe(object):\n",
        "    #resize and center image in desired size \n",
        "    def __init__(self,desired_size):\n",
        "        \n",
        "        self.desired_size = desired_size\n",
        "        \n",
        "    def __call__(self,img):\n",
        "    \n",
        "        img = np.array(img).astype(np.uint8)\n",
        "        \n",
        "        desired_ratio = self.desired_size[1] / self.desired_size[0]\n",
        "        actual_ratio = img.shape[0] / img.shape[1]\n",
        "\n",
        "        desired_ratio1 = self.desired_size[0] / self.desired_size[1]\n",
        "        actual_ratio1 = img.shape[1] / img.shape[0]\n",
        "\n",
        "        if desired_ratio < actual_ratio:\n",
        "            img = cv2.resize(img,(int(self.desired_size[1]*actual_ratio1),self.desired_size[1]),None,interpolation=cv2.INTER_AREA)\n",
        "        elif desired_ratio > actual_ratio:\n",
        "            img = cv2.resize(img,(self.desired_size[0],int(self.desired_size[0]*actual_ratio)),None,interpolation=cv2.INTER_AREA)\n",
        "        else:\n",
        "            img = cv2.resize(img,(self.desired_size[0], self.desired_size[1]),None, interpolation=cv2.INTER_AREA)\n",
        "            \n",
        "        h, w, _ = img.shape\n",
        "\n",
        "        new_img = np.zeros((self.desired_size[1],self.desired_size[0],3))\n",
        "        \n",
        "        hh, ww, _ = new_img.shape\n",
        "\n",
        "        yoff = int((hh-h)/2)\n",
        "        xoff = int((ww-w)/2)\n",
        "        \n",
        "        new_img[yoff:yoff+h, xoff:xoff+w,:] = img\n",
        "\n",
        "        \n",
        "        return Image.fromarray(new_img.astype(np.uint8))\n",
        "\n",
        "class MakeLandscape():\n",
        "    #flip if needed\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def __call__(self,img):\n",
        "        \n",
        "        if img.height> img.width:\n",
        "            img = np.rot90(np.array(img))\n",
        "            img = Image.fromarray(img)\n",
        "        return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp4FND70qpeK"
      },
      "source": [
        "# Inference Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yD6DkIeqpeK"
      },
      "source": [
        "### Load the predictor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:27:03.413794Z",
          "iopub.execute_input": "2021-11-03T02:27:03.414084Z",
          "iopub.status.idle": "2021-11-03T02:27:03.418058Z",
          "shell.execute_reply.started": "2021-11-03T02:27:03.414054Z",
          "shell.execute_reply": "2021-11-03T02:27:03.417257Z"
        },
        "trusted": true,
        "id": "XB9tNAIUqpeK"
      },
      "source": [
        "import os, json, cv2, random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:27:06.062556Z",
          "iopub.execute_input": "2021-11-03T02:27:06.062843Z",
          "iopub.status.idle": "2021-11-03T02:27:10.218665Z",
          "shell.execute_reply.started": "2021-11-03T02:27:06.062817Z",
          "shell.execute_reply": "2021-11-03T02:27:10.217930Z"
        },
        "trusted": true,
        "id": "v9WHYaktqpeL"
      },
      "source": [
        "predictor = get_predictor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSp4UgC_qpeL"
      },
      "source": [
        "### Get Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:27:29.151387Z",
          "iopub.execute_input": "2021-11-03T02:27:29.151699Z",
          "iopub.status.idle": "2021-11-03T02:27:29.474073Z",
          "shell.execute_reply.started": "2021-11-03T02:27:29.151669Z",
          "shell.execute_reply": "2021-11-03T02:27:29.473239Z"
        },
        "trusted": true,
        "id": "-Kyf-lewqpeL"
      },
      "source": [
        "img, img1 = get_cropped_leaf(Image.open(\"./plant-pathology-2020-fgvc7/images/Train_1254.jpg\"),predictor,return_mapping=True,resize = (512,int(512*.7)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:28:08.955911Z",
          "iopub.execute_input": "2021-11-03T02:28:08.956229Z",
          "iopub.status.idle": "2021-11-03T02:28:09.013146Z",
          "shell.execute_reply.started": "2021-11-03T02:28:08.956199Z",
          "shell.execute_reply": "2021-11-03T02:28:09.012271Z"
        },
        "trusted": true,
        "id": "fLA7GKN1qpeM"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:28:13.708390Z",
          "iopub.execute_input": "2021-11-03T02:28:13.708741Z",
          "iopub.status.idle": "2021-11-03T02:28:13.777462Z",
          "shell.execute_reply.started": "2021-11-03T02:28:13.708712Z",
          "shell.execute_reply": "2021-11-03T02:28:13.776673Z"
        },
        "trusted": true,
        "id": "dlUu6HnlqpeM"
      },
      "source": [
        "img1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efdDvo55qpeM"
      },
      "source": [
        "# Display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipHThnpqpeM"
      },
      "source": [
        "### Display of multiple images stacked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:30:48.686132Z",
          "iopub.execute_input": "2021-11-03T02:30:48.686433Z",
          "iopub.status.idle": "2021-11-03T02:31:08.510773Z",
          "shell.execute_reply.started": "2021-11-03T02:30:48.686403Z",
          "shell.execute_reply": "2021-11-03T02:31:08.509962Z"
        },
        "trusted": true,
        "id": "jB7fmJtaqpeN"
      },
      "source": [
        "final_image = []\n",
        "\n",
        "for x in range(75):\n",
        "    #select random image\n",
        "    file_loc = file_list[np.random.randint(0,len(file_list))]\n",
        "    #get outputs from predictor\n",
        "    img, img1 = get_cropped_leaf(Image.open(file_loc),predictor,return_mapping=True,resize = (600,int(600*.65)))\n",
        "    #stack horizontally\n",
        "    stacked = np.hstack([img,img1])\n",
        "    #append images\n",
        "    final_image.append(stacked)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:31:08.512315Z",
          "iopub.execute_input": "2021-11-03T02:31:08.512623Z",
          "iopub.status.idle": "2021-11-03T02:31:08.520059Z",
          "shell.execute_reply.started": "2021-11-03T02:31:08.512589Z",
          "shell.execute_reply": "2021-11-03T02:31:08.518401Z"
        },
        "trusted": true,
        "id": "9x2yq8-RqpeN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-11-03T02:31:17.099254Z",
          "iopub.execute_input": "2021-11-03T02:31:17.099582Z",
          "iopub.status.idle": "2021-11-03T02:31:47.117676Z",
          "shell.execute_reply.started": "2021-11-03T02:31:17.099552Z",
          "shell.execute_reply": "2021-11-03T02:31:47.116886Z"
        },
        "trusted": true,
        "id": "hJBIvyDlqpeN"
      },
      "source": [
        "for x in final_image:\n",
        "    fig = plt.figure(figsize=(20,10))\n",
        "    plt.imshow(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxsPY2yhqpeN"
      },
      "source": [
        "### I hope this has been some help to anyone who reads it. "
      ]
    }
  ]
}